## Unveiling Trends: Exploring News Mining with Latent Dirichlet Allocation


<img src="lda_img.png" alt="LDA" width="400">


- [Context](#context)
- [Introduction](#introduction)
   + [Data exploring](data_explorer.ipynb)
- [ML models](#ml-models)
   + [building the model](loyalty_drivers.ipynb)
- [Most important features](#most-important-features)
   + [building SHAP values](loyalty_drivers.ipynb)
- [Budget optimization](#budget-optimization)
   + [building the optimization model](optimizing_loyalty.ipynb)
- [What if scenario](#what-if-scenario)
   + [DiCE model](optimizing_loyalty.ipynb)
- [Findings](#findings)


## Context


*Latent Dirichlet Allocation (LDA)* is a popular algorithm used for topic modeling, which enables us to uncover hidden thematic structures within large collections of documents. It's particularly useful in fields like natural language processing and text mining for organizing, understanding, and summarizing large datasets of textual information


## Introduction


*Latent Dirichlet Allocation (LDA)* is a generative statistical model that explains a set of observations through unobserved groups. In the context of text analysis, these observations are words collected into documents, and it posits that each document is a mixture of a small number of topics and that each word's presence is attributable to one of the document's topics.
